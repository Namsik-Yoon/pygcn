{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled24.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN/H0U6h9qLexC5H+slACFk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Namsik-Yoon/pygcn/blob/master/experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPxrz-tf3HGK",
        "outputId": "c1a93308-3c34-4756-bc75-562da9739409"
      },
      "source": [
        "!git clone https://github.com/Namsik-Yoon/pygcn.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'pygcn' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puFuZMKk7UW4"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "os.chdir('/content/pygcn')\n",
        "sys.path.insert(1, '/content/pygcn')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNlNUkSl3J_-",
        "outputId": "80649725-6423-456c-cf52-d3bb4fe0ecc3"
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing pygcn.egg-info/PKG-INFO\n",
            "writing dependency_links to pygcn.egg-info/dependency_links.txt\n",
            "writing requirements to pygcn.egg-info/requires.txt\n",
            "writing top-level names to pygcn.egg-info/top_level.txt\n",
            "adding license file 'LICENCE'\n",
            "writing manifest file 'pygcn.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "copying pygcn/models.py -> build/lib/pygcn\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/pygcn\n",
            "copying build/lib/pygcn/__init__.py -> build/bdist.linux-x86_64/egg/pygcn\n",
            "copying build/lib/pygcn/train.py -> build/bdist.linux-x86_64/egg/pygcn\n",
            "copying build/lib/pygcn/layers.py -> build/bdist.linux-x86_64/egg/pygcn\n",
            "copying build/lib/pygcn/utils.py -> build/bdist.linux-x86_64/egg/pygcn\n",
            "copying build/lib/pygcn/models.py -> build/bdist.linux-x86_64/egg/pygcn\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pygcn/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pygcn/train.py to train.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pygcn/layers.py to layers.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pygcn/utils.py to utils.cpython-37.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/pygcn/models.py to models.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pygcn.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pygcn.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pygcn.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pygcn.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pygcn.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating 'dist/pygcn-0.1-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing pygcn-0.1-py3.7.egg\n",
            "Removing /usr/local/lib/python3.7/dist-packages/pygcn-0.1-py3.7.egg\n",
            "Copying pygcn-0.1-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "pygcn 0.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/pygcn-0.1-py3.7.egg\n",
            "Processing dependencies for pygcn==0.1\n",
            "Searching for scipy==1.4.1\n",
            "Best match: scipy 1.4.1\n",
            "Adding scipy 1.4.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torch==1.9.0+cu102\n",
            "Best match: torch 1.9.0+cu102\n",
            "Adding torch 1.9.0+cu102 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.19.5\n",
            "Best match: numpy 1.19.5\n",
            "Adding numpy 1.19.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==3.7.4.3\n",
            "Best match: typing-extensions 3.7.4.3\n",
            "Adding typing-extensions 3.7.4.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for pygcn==0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfYkpm5F92SZ"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfBhoSzwAA8d"
      },
      "source": [
        "def encode_onehot(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
        "                    enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
        "                             dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "def normalize(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8XtDHs_92Ug"
      },
      "source": [
        "path=\"/content/pygcn/data/cora/\"\n",
        "dataset=\"cora\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOLez-PeA4uj",
        "outputId": "1393e9d8-7b9b-4179-d798-fd3830a29b8e"
      },
      "source": [
        "## content 데이터 \n",
        "## [논문의 아이디,각 논문의 feature, 논문의 장르]\n",
        "idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset),\n",
        "                                        dtype=np.dtype(str))\n",
        "idx_features_labels"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['31336', '0', '0', ..., '0', '0', 'Neural_Networks'],\n",
              "       ['1061127', '0', '0', ..., '0', '0', 'Rule_Learning'],\n",
              "       ['1106406', '0', '0', ..., '0', '0', 'Reinforcement_Learning'],\n",
              "       ...,\n",
              "       ['1128978', '0', '0', ..., '0', '0', 'Genetic_Algorithms'],\n",
              "       ['117328', '0', '0', ..., '0', '0', 'Case_Based'],\n",
              "       ['24043', '0', '0', ..., '0', '0', 'Neural_Networks']],\n",
              "      dtype='<U22')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXutsacB92Wb"
      },
      "source": [
        "## 각 논문의 feature\n",
        "features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
        "## 논문의 장르(onehot)\n",
        "labels = encode_onehot(idx_features_labels[:, -1])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksOmyezT92Y5"
      },
      "source": [
        "idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
        "idx_map = {j: i for i, j in enumerate(idx)} ## 논문 id 맵핑 dict"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhdt1cIU92as"
      },
      "source": [
        "## cite 데이터\n",
        "## [참조된 논문, 참조한 논문]\n",
        "edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset),\n",
        "                                dtype=np.int32)\n",
        "edges = np.array(list(map(idx_map.get, edges_unordered.flatten())),\n",
        "                    dtype=np.int32).reshape(edges_unordered.shape)\n",
        "\n",
        "## cite 데이터로 directed graph의 adj matrix 생성\n",
        "adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])),\n",
        "                    shape=(labels.shape[0], labels.shape[0]),\n",
        "                    dtype=np.float32)\n",
        "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvGcJNerAt1W"
      },
      "source": [
        "features = normalize(features)\n",
        "adj = normalize(adj + sp.eye(adj.shape[0]))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A44b-hWtAt5N"
      },
      "source": [
        "features = torch.FloatTensor(np.array(features.todense()))\n",
        "labels = torch.LongTensor(np.where(labels)[1])\n",
        "adj = sparse_mx_to_torch_sparse_tensor(adj)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asJY-NVdAt7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90755040-9814-43d2-9a84-214c0ef601c5"
      },
      "source": [
        "features,features.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "         [0., 0., 0.,  ..., 0., 0., 0.]]), torch.Size([2708, 1433]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLn5ug_YAt9Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2898d95-8bbe-410d-a5c6-646b71866f4b"
      },
      "source": [
        "labels,labels.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([5, 1, 0,  ..., 2, 4, 5]), torch.Size([2708]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwkWW7h7At_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac0aaedf-ea8e-4ee1-a173-fbbae7debffa"
      },
      "source": [
        "adj,adj.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(indices=tensor([[   0,    8,   14,  ..., 1389, 2344, 2707],\n",
              "                        [   0,    0,    0,  ..., 2707, 2707, 2707]]),\n",
              "        values=tensor([0.1667, 0.1667, 0.0500,  ..., 0.2000, 0.5000, 0.2500]),\n",
              "        size=(2708, 2708), nnz=13264, layout=torch.sparse_coo),\n",
              " torch.Size([2708, 2708]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubs4CnUFxBp4"
      },
      "source": [
        "idx_train = torch.LongTensor(range(1200))\n",
        "idx_val = torch.LongTensor(range(1200,1500))\n",
        "idx_test = torch.LongTensor(range(1500,2708))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S7zvSfPxB7z"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "random_seed = 2021\n",
        "torch.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed(random_seed)\n",
        "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "np.random.seed(random_seed)\n",
        "random.seed(random_seed)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-z1gCCxAuBi"
      },
      "source": [
        "class GCN_layer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, A):\n",
        "        super(GCN_layer, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.A = A\n",
        "        self.fc = nn.Linear(in_features, out_features)\n",
        "        \n",
        "    def forward(self, X):\n",
        "        return self.fc(torch.spmm(self.A, X)) #이웃 정보 종합\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, num_feature, num_class, A):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "                                    GCN_layer(num_feature, 16, A),\n",
        "                                    nn.ReLU(),\n",
        "                                    GCN_layer(16, num_class, A)\n",
        "                                )\n",
        "        \n",
        "    def forward(self, X):\n",
        "        return self.feature_extractor(X)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hwrnUlzw4rS"
      },
      "source": [
        "class FCN(nn.Module):\n",
        "    def __init__(self, num_feature, num_class):\n",
        "        super(FCN, self).__init__()\n",
        "\n",
        "        self.feature_extractor = nn.Sequential(\n",
        "                                    nn.Linear(num_feature, 16),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Linear(16, num_class)\n",
        "                                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.feature_extractor(x)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWUy20jMw4tX"
      },
      "source": [
        "def train(model, Loss, optimizer, num_epochs):\n",
        "  train_loss_arr = []\n",
        "  test_loss_arr = []\n",
        "\n",
        "  best_test_loss = 99999999\n",
        "  best_ACC = 0\n",
        "  early_stop, early_stop_max = 0., 10.\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "    # Forward Pass\n",
        "    model.train()\n",
        "    output = model(features)\n",
        "    train_loss = criterion(output[idx_train], labels[idx_train])\n",
        "\n",
        "    # Backward and optimize\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "        \n",
        "    train_loss_arr.append(train_loss.data)\n",
        "    \n",
        "    if epoch % 20 == 0:\n",
        "        model.eval()\n",
        "        \n",
        "        output = model(features)\n",
        "        val_loss = criterion(output[idx_val], labels[idx_val])\n",
        "        test_loss = criterion(output[idx_test], labels[idx_test])\n",
        "        \n",
        "        val_acc = accuracy(output[idx_val], labels[idx_val])\n",
        "        test_acc = accuracy(output[idx_test], labels[idx_test])\n",
        "        \n",
        "        test_loss_arr.append(test_loss)\n",
        "        \n",
        "        if best_ACC < val_acc:\n",
        "            best_ACC = val_acc\n",
        "            early_stop = 0\n",
        "            final_ACC = test_acc\n",
        "            print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f}, Test ACC: {:.4f} *'.format(epoch, num_epochs, train_loss.data, test_loss, test_acc))\n",
        "        else:\n",
        "            early_stop += 1\n",
        "\n",
        "            print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f}, Test ACC: {:.4f}'.format(epoch, num_epochs, train_loss.data, test_loss, test_acc))\n",
        "\n",
        "    if early_stop >= early_stop_max:\n",
        "        break\n",
        "        \n",
        "  print(\"Final Accuracy::\", final_ACC)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug6eFhzMx8iG"
      },
      "source": [
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvQelRO9w4v0",
        "outputId": "ef06841f-d241-42da-a8cf-d0a8964fc86e"
      },
      "source": [
        "# FCN 학습 돌려서 epoch에 따른 Loss 확인\n",
        "model = FCN(features.size(1) , labels.unique().size(0))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
        "\n",
        "train(model, criterion, optimizer, 1000)\n",
        "\n",
        "\n",
        "# GCN 학습 돌려서 epoch에 따른 Loss 확인\n",
        "model = GCN(features.size(1) , labels.unique().size(0), adj)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0001)\n",
        "\n",
        "train(model, criterion, optimizer, 1000)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0/1000], Train Loss: 1.9693, Test Loss: 1.9561, Test ACC: 0.0952 *\n",
            "Epoch [20/1000], Train Loss: 1.7135, Test Loss: 1.7701, Test ACC: 0.2864 *\n",
            "Epoch [40/1000], Train Loss: 1.4001, Test Loss: 1.6211, Test ACC: 0.3187 *\n",
            "Epoch [60/1000], Train Loss: 1.2610, Test Loss: 1.5977, Test ACC: 0.4536 *\n",
            "Epoch [80/1000], Train Loss: 0.6459, Test Loss: 1.2421, Test ACC: 0.5381 *\n",
            "Epoch [100/1000], Train Loss: 1.1286, Test Loss: 2.2688, Test ACC: 0.4040\n",
            "Epoch [120/1000], Train Loss: 0.7650, Test Loss: 1.7546, Test ACC: 0.5141\n",
            "Epoch [140/1000], Train Loss: 1.0105, Test Loss: 2.0794, Test ACC: 0.4652\n",
            "Epoch [160/1000], Train Loss: 1.1740, Test Loss: 3.0651, Test ACC: 0.3601\n",
            "Epoch [180/1000], Train Loss: 0.7834, Test Loss: 2.8174, Test ACC: 0.4636\n",
            "Epoch [200/1000], Train Loss: 0.8743, Test Loss: 2.9947, Test ACC: 0.4743\n",
            "Epoch [220/1000], Train Loss: 0.5856, Test Loss: 2.6093, Test ACC: 0.5455\n",
            "Epoch [240/1000], Train Loss: 0.7827, Test Loss: 3.2212, Test ACC: 0.5397\n",
            "Epoch [260/1000], Train Loss: 0.9442, Test Loss: 3.8637, Test ACC: 0.5108\n",
            "Epoch [280/1000], Train Loss: 0.7186, Test Loss: 3.2754, Test ACC: 0.5281\n",
            "Final Accuracy:: tensor(0.5381, dtype=torch.float64)\n",
            "Epoch [0/1000], Train Loss: 1.9737, Test Loss: 1.9819, Test ACC: 0.0662 *\n",
            "Epoch [20/1000], Train Loss: 1.7894, Test Loss: 1.7949, Test ACC: 0.2848 *\n",
            "Epoch [40/1000], Train Loss: 1.6984, Test Loss: 1.7731, Test ACC: 0.2881\n",
            "Epoch [60/1000], Train Loss: 1.5902, Test Loss: 1.6376, Test ACC: 0.3626 *\n",
            "Epoch [80/1000], Train Loss: 1.5641, Test Loss: 1.6050, Test ACC: 0.3154 *\n",
            "Epoch [100/1000], Train Loss: 1.1852, Test Loss: 1.3263, Test ACC: 0.5182 *\n",
            "Epoch [120/1000], Train Loss: 1.1780, Test Loss: 1.4910, Test ACC: 0.4892\n",
            "Epoch [140/1000], Train Loss: 1.7833, Test Loss: 2.1889, Test ACC: 0.3435\n",
            "Epoch [160/1000], Train Loss: 1.2448, Test Loss: 1.6930, Test ACC: 0.5298\n",
            "Epoch [180/1000], Train Loss: 1.1603, Test Loss: 1.6642, Test ACC: 0.4727\n",
            "Epoch [200/1000], Train Loss: 1.4218, Test Loss: 1.8936, Test ACC: 0.3775\n",
            "Epoch [220/1000], Train Loss: 1.4257, Test Loss: 1.6415, Test ACC: 0.4553\n",
            "Epoch [240/1000], Train Loss: 1.2825, Test Loss: 1.4448, Test ACC: 0.4868\n",
            "Epoch [260/1000], Train Loss: 0.8616, Test Loss: 1.2346, Test ACC: 0.6316 *\n",
            "Epoch [280/1000], Train Loss: 0.8247, Test Loss: 1.2570, Test ACC: 0.5646\n",
            "Epoch [300/1000], Train Loss: 0.7202, Test Loss: 1.0818, Test ACC: 0.6457\n",
            "Epoch [320/1000], Train Loss: 0.6824, Test Loss: 1.1764, Test ACC: 0.6291\n",
            "Epoch [340/1000], Train Loss: 0.9304, Test Loss: 1.6786, Test ACC: 0.5563\n",
            "Epoch [360/1000], Train Loss: 1.0306, Test Loss: 1.7747, Test ACC: 0.5911\n",
            "Epoch [380/1000], Train Loss: 0.9202, Test Loss: 1.5068, Test ACC: 0.6772 *\n",
            "Epoch [400/1000], Train Loss: 0.7106, Test Loss: 1.2133, Test ACC: 0.7194\n",
            "Epoch [420/1000], Train Loss: 0.8750, Test Loss: 1.6206, Test ACC: 0.6200\n",
            "Epoch [440/1000], Train Loss: 1.2779, Test Loss: 2.3036, Test ACC: 0.5298\n",
            "Epoch [460/1000], Train Loss: 1.0383, Test Loss: 2.2817, Test ACC: 0.5389\n",
            "Epoch [480/1000], Train Loss: 1.0519, Test Loss: 2.2861, Test ACC: 0.5762\n",
            "Epoch [500/1000], Train Loss: 1.1463, Test Loss: 2.4099, Test ACC: 0.5687\n",
            "Epoch [520/1000], Train Loss: 1.0395, Test Loss: 2.0292, Test ACC: 0.4975\n",
            "Epoch [540/1000], Train Loss: 1.0370, Test Loss: 1.7494, Test ACC: 0.5613\n",
            "Epoch [560/1000], Train Loss: 0.9037, Test Loss: 1.6580, Test ACC: 0.6192 *\n",
            "Epoch [580/1000], Train Loss: 0.8087, Test Loss: 1.9558, Test ACC: 0.7053 *\n",
            "Epoch [600/1000], Train Loss: 1.1314, Test Loss: 2.7747, Test ACC: 0.6912\n",
            "Epoch [620/1000], Train Loss: 1.5166, Test Loss: 3.6481, Test ACC: 0.6316\n",
            "Epoch [640/1000], Train Loss: 1.4862, Test Loss: 3.7789, Test ACC: 0.6175\n",
            "Epoch [660/1000], Train Loss: 1.0934, Test Loss: 3.1077, Test ACC: 0.6316\n",
            "Epoch [680/1000], Train Loss: 0.7543, Test Loss: 2.2623, Test ACC: 0.6730\n",
            "Epoch [700/1000], Train Loss: 0.7244, Test Loss: 1.9623, Test ACC: 0.7376 *\n",
            "Epoch [720/1000], Train Loss: 0.8027, Test Loss: 2.1842, Test ACC: 0.7210\n",
            "Epoch [740/1000], Train Loss: 1.0293, Test Loss: 2.6311, Test ACC: 0.7020\n",
            "Epoch [760/1000], Train Loss: 1.1534, Test Loss: 2.8830, Test ACC: 0.6945\n",
            "Epoch [780/1000], Train Loss: 0.9849, Test Loss: 2.6008, Test ACC: 0.6929\n",
            "Epoch [800/1000], Train Loss: 1.0032, Test Loss: 2.4715, Test ACC: 0.6507\n",
            "Epoch [820/1000], Train Loss: 1.2113, Test Loss: 2.7119, Test ACC: 0.6018\n",
            "Epoch [840/1000], Train Loss: 1.2389, Test Loss: 2.7974, Test ACC: 0.6084\n",
            "Epoch [860/1000], Train Loss: 1.1797, Test Loss: 2.8178, Test ACC: 0.6374\n",
            "Epoch [880/1000], Train Loss: 1.0959, Test Loss: 2.8135, Test ACC: 0.6623\n",
            "Epoch [900/1000], Train Loss: 0.9732, Test Loss: 2.7793, Test ACC: 0.6540\n",
            "Final Accuracy:: tensor(0.7376, dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYiv6UnyLmsF"
      },
      "source": [
        ""
      ],
      "execution_count": 53,
      "outputs": []
    }
  ]
}